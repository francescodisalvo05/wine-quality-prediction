{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine quality prediction\n",
    "\n",
    "## Import and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(directory):\n",
    "    df = pd.read_csv(directory,sep=\"\\t\")\n",
    "    return df\n",
    "\n",
    "def get_final_csv(ids, y, filename):\n",
    "    pd.DataFrame(dict(Id = ids,Predicted = y)).to_csv(filename,sep=\",\",index=False)\n",
    "\n",
    "def evaluateModels(models,targets,X,y):\n",
    "    \n",
    "    scores = pd.DataFrame()\n",
    "    \n",
    "    for model,target in zip(models,targets):\n",
    "        cv = RepeatedKFold(n_splits=3, n_repeats=1, random_state=42)\n",
    "        scores[target] = cross_val_score(model, X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "        \n",
    "        print(f\"{target} ended up\")\n",
    "        \n",
    "    return scores\n",
    "\n",
    "\"\"\"\n",
    "    1) OneHot encoding\n",
    "\"\"\"\n",
    "def preprocessingV1(X_d,X_e):\n",
    "    \n",
    "    X_d = X_d.drop(columns=[\"region_2\",\"description\"])\n",
    "    X_e = X_e.drop(columns=[\"region_2\",\"description\"])\n",
    "\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    X_d[\"country\"] = imputer.fit_transform(np.array(X_d[\"country\"]).reshape(-1,1))\n",
    "    X_d[\"province\"] = imputer.fit_transform(np.array(X_d[\"province\"]).reshape(-1,1))\n",
    "    \n",
    "    X_d = X_d.fillna(\"other\")\n",
    "    X_e = X_e.fillna(\"other\")\n",
    "    \n",
    "    y = X_d.quality\n",
    "    X_d = X_d.drop(columns=[\"quality\"])\n",
    "    \n",
    "    df = pd.concat([X_d,X_e])\n",
    "    \n",
    "    df_enc = pd.get_dummies(df)\n",
    "    df_enc_scipy = scipy.sparse.csr_matrix(df_enc.values)\n",
    "    \n",
    "    return df_enc_scipy[:X_d.shape[0]], y, df_enc_scipy[X_d.shape[0]:]\n",
    "\n",
    "\"\"\"\n",
    "    2) OneHot encoding without outliers\n",
    "\"\"\"\n",
    "def preprocessingV3(X_d,X_e):\n",
    "    \n",
    "    X_d = X_d.drop(columns=[\"region_2\",\"description\"])\n",
    "    X_e = X_e.drop(columns=[\"region_2\",\"description\"])\n",
    "    \n",
    "    X_d = X_d.fillna(\"other\")\n",
    "    X_e = X_e.fillna(\"other\")\n",
    "    \n",
    "    # 1.5(IQR) Rule for detecting the outliers\n",
    "    t = X_d[\"quality\"].quantile(0.75) - X_d[\"quality\"].quantile(0.25)\n",
    "    min_t = X_d[\"quality\"].quantile(0.25) - 1.5 * t\n",
    "    max_t = X_d[\"quality\"].quantile(0.75) + 1.5 * t\n",
    "    \n",
    "    X_d_filtered = X_d[X_d[\"quality\"] >= min_t]\n",
    "    X_d_filtered = X_d_filtered[X_d_filtered[\"quality\"] <= max_t]\n",
    "    \n",
    "    y = X_d_filtered.quality\n",
    "    \n",
    "    df = pd.concat([X_d_filtered,X_e])\n",
    "    \n",
    "    df_enc = pd.get_dummies(df)\n",
    "    df_enc_scipy = scipy.sparse.csr_matrix(df_enc.values)\n",
    "    \n",
    "    return df_enc_scipy[:X_d_filtered.shape[0]], y, df_enc_scipy[X_d_filtered.shape[0]:]\n",
    "\n",
    "\"\"\"\n",
    "    3) OneHot encoding without outliers\n",
    "\"\"\"\n",
    "def preprocessingV3(X_d,X_e):\n",
    "    \n",
    "    X_d = X_d.drop(columns=[\"region_2\",\"description\"])\n",
    "    X_e = X_e.drop(columns=[\"region_2\",\"description\"])\n",
    "    \n",
    "    X_d = X_d.fillna(\"other\")\n",
    "    X_e = X_e.fillna(\"other\")\n",
    "    \n",
    "    # 1.5(IQR) Rule for detecting the outliers\n",
    "    t = X_d[\"quality\"].quantile(0.75) - X_d[\"quality\"].quantile(0.25)\n",
    "    min_t = X_d[\"quality\"].quantile(0.25) - 1.5 * t\n",
    "    max_t = X_d[\"quality\"].quantile(0.75) + 1.5 * t\n",
    "    \n",
    "    X_d_filtered = X_d[X_d[\"quality\"] >= min_t]\n",
    "    X_d_filtered = X_d_filtered[X_d_filtered[\"quality\"] <= max_t]\n",
    "    \n",
    "    y = X_d_filtered.quality\n",
    "    \n",
    "    df = pd.concat([X_d_filtered,X_e])\n",
    "    \n",
    "    df_enc = pd.get_dummies(df)\n",
    "    df_enc_scipy = scipy.sparse.csr_matrix(df_enc.values)\n",
    "    \n",
    "    return df_enc_scipy[:X_d_filtered.shape[0]], y, df_enc_scipy[X_d_filtered.shape[0]:]\n",
    "\n",
    "\"\"\"\n",
    "    4) OneHot encoding without duplicates\n",
    "\"\"\"\n",
    "def preprocessingV4(X_d,X_e):\n",
    "    \n",
    "    X_d = X_d.drop(columns=[\"region_2\",\"description\"])\n",
    "    X_e = X_e.drop(columns=[\"region_2\",\"description\"])\n",
    "    \n",
    "    X_d = X_d.fillna(\"other\")\n",
    "    X_d = X_d.drop_duplicates()\n",
    "    X_e = X_e.fillna(\"other\")\n",
    "    \n",
    "    y = X_d.quality\n",
    "    X_d = X_d.drop(columns=[\"quality\"])\n",
    "    \n",
    "    df = pd.concat([X_d,X_e])\n",
    "    \n",
    "    df_enc = pd.get_dummies(df)\n",
    "    df_enc_scipy = scipy.sparse.csr_matrix(df_enc.values)\n",
    "    \n",
    "    return df_enc_scipy[:X_d.shape[0]], y, df_enc_scipy[X_d.shape[0]:]\n",
    "\n",
    "\"\"\"\n",
    "    5) OneHot encoding of the top 80% elements per feature\n",
    "\"\"\"\n",
    "def preprocessingV5(X_d,X_e,labels):\n",
    "    \n",
    "    X_d = X_d.drop(columns=[\"region_2\",\"description\"])\n",
    "    X_e = X_e.drop(columns=[\"region_2\",\"description\"])\n",
    "    \n",
    "    X_d = X_d.fillna(\"other\")\n",
    "    X_e = X_e.fillna(\"other\")\n",
    "    \n",
    "    y = X_d.quality\n",
    "    X_d = X_d.drop(columns=[\"quality\"])\n",
    "    \n",
    "    df = pd.concat([X_d,X_e])\n",
    "    \n",
    "    for label in labels:\n",
    "        \n",
    "        top_labels_index = df[label].value_counts().index\n",
    "        top_labels_length = len(df[label].value_counts().index)\n",
    "        thresh = round(top_labels_length * 80 / 100)\n",
    "        thresh = top_labels_length\n",
    "        \n",
    "        top = df[label].isin(top_labels_index[:thresh])\n",
    "        df.loc[~top, label] = \"other\"\n",
    "    \n",
    "    df_enc = scipy.sparse.csr_matrix(pd.get_dummies(df).values)\n",
    "    \n",
    "    return df_enc[:X_d.shape[0]], y, df_enc[X_d.shape[0]:]\n",
    "\n",
    "## extra\n",
    "models = [LinearRegression(),RandomForestRegressor(),SGDRegressor()]\n",
    "targets = [\"Linear Regression\",\"Random Forest\",\"SGD Regressor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## OneHot Encoding\n",
    "########################################\n",
    "\n",
    "%%time\n",
    "\n",
    "X_dev_v1 = loadData('Dataset/dev.tsv')\n",
    "X_eval_v1 = loadData('Dataset/eval.tsv')\n",
    "\n",
    "X_dev_v1_prep, y1, X_eval_v1_prep = preprocessingV1(X_dev_v1,X_eval_v1)\n",
    "\n",
    "scores_1 = evaluateModels(models,targets,X_dev_v1_prep,y1)\n",
    "scores_1.to_csv(\"scores-v1.csv\",sep=\",\",index=False)\n",
    "\n",
    "X_dev_v1_prep.shape, y1.shape, X_eval_v1_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_1 = RandomForestRegressor()\n",
    "rf_1.fit(X_dev_v1_prep,y1)\n",
    "\n",
    "y_pred_1 = rf_1.predict(X_eval_v1_prep)\n",
    "get_csv(list(X_eval_v1.index),y_pred_1,\"submission_prep_v1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## OneHot Encoding + removing outliers\n",
    "########################################\n",
    "\n",
    "%%time\n",
    "\n",
    "X_dev_v2 = loadData('Dataset/dev.tsv')\n",
    "X_eval_v2 = loadData('Dataset/eval.tsv')\n",
    "\n",
    "X_dev_v2_prep, y2, X_eval_v2_prep = preprocessingV2(X_dev_v2,X_eval_v2)\n",
    "\n",
    "scores_2= evaluateModels(models,targets,X_dev_v2_prep,y2)\n",
    "scores_2.to_csv(\"scores-v2.csv\",sep=\",\",index=False)\n",
    "\n",
    "X_dev_v2_prep.shape, y2.shape, X_eval_v2_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_2 = RandomForestRegressor()\n",
    "rf_2.fit(X_dev_v2_prep,y2)\n",
    "\n",
    "y_pred_2 = rf_2.predict(X_eval_v2_prep)\n",
    "get_csv(list(X_eval_v2.index),y_pred_2,\"submission_prep_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## OneHot Encoding + removing duplicates\n",
    "########################################\n",
    "\n",
    "%%time\n",
    "\n",
    "X_dev_v3 = loadData('Dataset/dev.tsv')\n",
    "X_eval_v3 = loadData('Dataset/eval.tsv')\n",
    "\n",
    "X_dev_v3_prep, y3, X_eval_v3_prep = preprocessingV3(X_dev_v3,X_eval_v3)\n",
    "\n",
    "scores_3 = evaluateModels(models,targets,X_dev_v3_prep,y3)\n",
    "scores_3.to_csv(\"scores-v3.csv\",sep=\",\",index=False)\n",
    "\n",
    "X_dev_v3_prep.shape, y3.shape, X_eval_v3_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_3 = RandomForestRegressor()\n",
    "rf_3.fit(X_dev_v3_prep,y3)\n",
    "\n",
    "y_pred_3 = rf_3.predict(X_eval_v3_prep)\n",
    "get_csv(list(X_eval_v3.index),y_pred_3,\"submission_prep_v3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## OneHot Encoding + \n",
    "########################################\n",
    "\n",
    "X_dev_v4 = loadData('Dataset/dev.tsv')\n",
    "X_eval_v4 = loadData('Dataset/eval.tsv')\n",
    "\n",
    "X_dev_v4_prep, y4, X_eval_v4_prep = preprocessingV4(X_dev_v4,X_eval_v4)\n",
    "\n",
    "scores_4 = evaluateModels(models,targets,X_dev_v4_prep,y4)\n",
    "scores_4.to_csv(\"scores-v4.csv\",sep=\",\",index=False)\n",
    "\n",
    "X_dev_v4_prep.shape, y4.shape, X_eval_v4_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_4 = RandomForestRegressor()\n",
    "rf_4.fit(X_dev_v4_prep,y4)\n",
    "\n",
    "y_pred_4 = rf_4.predict(X_eval_v4_prep)\n",
    "get_csv(list(X_eval_v4.index),y_pred_4,\"submission_prep_v4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## OneHot Encoding of top 80% elements\n",
    "########################################\n",
    "\n",
    "X_dev_v5 = loadData('Dataset/dev.tsv')\n",
    "X_eval_v5 = loadData('Dataset/eval.tsv')\n",
    "\n",
    "X_dev_v5_prep, y5, X_eval_v5_prep = preprocessingV5(X_dev_v5,X_eval_v5)\n",
    "\n",
    "scores_5 = evaluateModels(models,targets,X_dev_v5_prep,y5)\n",
    "scores_5.to_csv(\"scores-v5.csv\",sep=\",\",index=False)\n",
    "\n",
    "X_dev_v5_prep.shape, y5.shape, X_eval_v5_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_5 = RandomForestRegressor()\n",
    "rf_5.fit(X_dev_v5_prep,y5)\n",
    "\n",
    "y_pred_5 = rf_5.predict(X_eval_v5_prep)\n",
    "get_csv(list(X_eval_v5.index),y_pred_5,\"submission_prep_v5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphs\n",
    "\n",
    "Œ≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test_1 = pd.read_csv('Report tools/preprocessing-scores/scores-v1_Naive.csv')\n",
    "result_test_1[\"version\"] = \"Œ±\"\n",
    "result_test_1[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_test_3 = pd.read_csv('Report tools/preprocessing-scores/scores-v3_NoDupl.csv')\n",
    "result_test_3[\"version\"] = \"ùõæ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear Regression</th>\n",
       "      <th>Random Forest</th>\n",
       "      <th>SGD Regressor</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.602699</td>\n",
       "      <td>0.637474</td>\n",
       "      <td>0.625160</td>\n",
       "      <td>ùõæ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.607276</td>\n",
       "      <td>0.640737</td>\n",
       "      <td>0.634599</td>\n",
       "      <td>ùõæ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.593194</td>\n",
       "      <td>0.628418</td>\n",
       "      <td>0.614859</td>\n",
       "      <td>ùõæ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Linear Regression  Random Forest  SGD Regressor version\n",
       "0           0.602699       0.637474       0.625160       ùõæ\n",
       "1           0.607276       0.640737       0.634599       ùõæ\n",
       "2           0.593194       0.628418       0.614859       ùõæ"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([result_test_1,result_test_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-add695c85ac4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Linear Regression\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"version\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'count' is not defined"
     ]
    }
   ],
   "source": [
    "sns.barplot(x=\"Linear Regression\", y=count, hue=\"version\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
