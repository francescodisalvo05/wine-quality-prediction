{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(directory):\n",
    "    \n",
    "    df = pd.read_csv(directory,sep=\"\\t\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "X_dev = loadData('Dataset/dev.tsv')\n",
    "X_eval = loadData('Dataset/eval.tsv')\n",
    "\n",
    "X_dev['length_description'] = X_dev['description'].apply(lambda x : len(x))\n",
    "X_dev = X_dev.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                   3\n",
       "description               0\n",
       "designation           25944\n",
       "province                  3\n",
       "region_1              13889\n",
       "region_2              50734\n",
       "variety                   0\n",
       "winery                    0\n",
       "quality                   0\n",
       "length_description        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    * Hashing\\n    * Replace each value with its count -> Take care about the same value in the eval\\n    * map just a subset of elements (by selecting a treshold)\\n\\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TRY THESE TWO ENCODING WAYS\n",
    "\n",
    "\"\"\"\n",
    "    * Hashing\n",
    "    * Replace each value with its count -> Take care about the same value in the eval\n",
    "    * map just a subset of elements (by selecting a treshold)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prep = X_dev.drop(columns=['description','designation','region_1','region_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doPreprocV1(X,labels):\n",
    "    X = X.fillna(0)\n",
    "    for label in labels:\n",
    "        X[label] = X[label].map(X[label].value_counts().to_dict())\n",
    "        \n",
    "    return X\n",
    "\n",
    "def doPreprocV2(X,labels):\n",
    "    X = X.fillna(\"default\")\n",
    "    for label in labels:\n",
    "        X[label] = X.apply(lambda x : hash(x[label]),axis=1)\n",
    "\n",
    "    return X\n",
    "\n",
    "def doPreprocV3(X,labels1,labels2):\n",
    "    X = X.fillna(0)\n",
    "    for label in labels1:\n",
    "        X[label] = X[label].map(X[label].value_counts().to_dict())\n",
    "    \n",
    "    for label in labels2:\n",
    "        X[label] = X.apply(lambda x : hash(x[label]),axis=1)\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country               3\n",
       "province              3\n",
       "variety               0\n",
       "winery                0\n",
       "quality               0\n",
       "length_description    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_prep.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prep_v2 = doPreprocV2(X_prep,['country','province','variety','winery'])\n",
    "y = X_prep_v2.quality\n",
    "X = X_prep_v2.drop(columns=['quality'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode with average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "\\# -- specificare la misura di riferimento (accuracy o altro) <br /><br />\n",
    "In order to tune the best models, we tested #tot different classifiers with their default hyperparameters through the Repeated K-Fold Cross Validation. This gives a more “robust” model assessment score rather than the fairly well known K-Fold Cross Validation, because it run several times. In this case we used 5 folds and 10 ierations. The algorithms that we tested are: \n",
    "- **\n",
    "- **\n",
    "\n",
    "The output of the the Cross Validation phase can be clearly seen in Figure # . So we decided to tune the \\\\ and the \\\\ classifiers trough the Grid Search, as explained in the next section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "randomforest = RandomForestRegressor()\n",
    "linearregression = LinearRegression()\n",
    "sgd = SGDRegressor()\n",
    "\n",
    "#polynomialregression = make_pipeline(PolynomialFeatures(10), LinearRegression())\n",
    "#polynomialregression.fit(X, y)\n",
    "\n",
    "\n",
    "models = [randomforest]\n",
    "targets = [\"RandomForest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModels(models, targets,X,y):\n",
    "    \n",
    "    scores = pd.DataFrame()\n",
    "    \n",
    "    for model,target in zip(models,targets):\n",
    "        cv = RepeatedKFold(n_splits=10, n_repeats=5, random_state=42)\n",
    "        scores[target] = cross_val_score(model, X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy ***')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = evaluateModels(models,targets,X,y)\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(scores))\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Accuracy ***\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "In order to improve the performances of the selected models we used the GridSearchCV that performs a Cross Validation over all the combinations of a given set of hyperparameters. Since we had enough data, we used the hold out technique, so we considered 80% for the train data and the remaining 20% for the testing the models. \n",
    "\n",
    "## Results\n",
    "The results of the hyperparameters tuning can be seen in Table ##. Apparently they all outperformed their naive solutions and \\[brodo\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doGridSearch(model,model_name,hyperparams,X,y):\n",
    "    gs = GridSearchCV(estimator=model,  \n",
    "                         param_grid=hyperparams,\n",
    "                         scoring='r2',\n",
    "                         cv=5,\n",
    "                         n_jobs=-1,\n",
    "                         verbose=True)\n",
    "\n",
    "    gs.fit(X, y)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_RF = {\n",
    "    \"n_estimators\": [100, 200, 500],\n",
    "    \"criterion\": [\"mse\", \"mae\"],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"random_state\": [42],# always use the samet random seed\n",
    "    \"n_jobs\": [-1],# for parallelization\n",
    "}\n",
    "\n",
    "#gridsearch_models = [\"Random Forest\"]\n",
    "#classifiers = [RandomForestRegressor()]\n",
    "#hyperparams_list = [hyperparams_RF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ntuning_table = PrettyTable()\\ntuning_table.field_names = ['MODEL', 'BEST ACCURACY']\\n\\nfor name,params,clf in zip(gridsearch_models,hyperparams_list,classifiers):\\n    \\n    tuning_table.add_row(doGridSearch(clf,name,params,X,y))\\n    \\nprint(tuning_table)\\n\\n\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "tuning_table = PrettyTable()\n",
    "tuning_table.field_names = ['MODEL', 'BEST ACCURACY']\n",
    "\n",
    "for name,params,clf in zip(gridsearch_models,hyperparams_list,classifiers):\n",
    "    \n",
    "    tuning_table.add_row(doGridSearch(clf,name,params,X,y))\n",
    "    \n",
    "print(tuning_table)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  4.9min\n"
     ]
    }
   ],
   "source": [
    "gs = doGridSearch(RandomForestRegressor(), \"RandomForestRegressor\",hyperparams_RF,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best params:\\t{gs.best_params_}\")\n",
    "print(f\"Best score:\\t{gs.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(ids, y):\n",
    "    pd.DataFrame(dict(Id = ids,Predicted = y)).to_csv(\"submission1.csv\",sep=\",\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploys history\n",
    "\n",
    "* submission1 [data/ora] -> parametri e preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## //Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
