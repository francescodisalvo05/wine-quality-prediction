{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Francesco Di Salvo - S282414\n",
    "# Wine Quality Prediction\n",
    "\n",
    "## Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression,SGDRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import scipy\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(directory):\n",
    "    df = pd.read_csv(directory,sep=\"\\t\")\n",
    "    return df\n",
    "\n",
    "def get_final_csv(ids, y, filename):\n",
    "    pd.DataFrame(dict(Id = ids,Predicted = y)).to_csv(filename,sep=\",\",index=False)\n",
    "    \n",
    "def evaluateModels(models, targets,X,y):\n",
    "    \n",
    "    scores = pd.DataFrame()\n",
    "    for model,target in zip(models,targets):\n",
    "        scores[target] = cross_val_score(model, X, y, scoring='r2', cv=3, n_jobs=-1)\n",
    "        \n",
    "    return scores\n",
    "\n",
    "##################################  \n",
    "## Encoding and Missing values\n",
    "##################################\n",
    "def preprocessing(X_d,X_e):\n",
    "    \n",
    "    X_d = X_d.drop(columns=[\"region_2\",\"description\"])\n",
    "    X_e = X_e.drop(columns=[\"region_2\",\"description\"])\n",
    "\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "    X_d[\"country\"] = imputer.fit_transform(np.array(X_d[\"country\"]).reshape(-1,1))\n",
    "    X_d[\"province\"] = imputer.fit_transform(np.array(X_d[\"province\"]).reshape(-1,1))\n",
    "    \n",
    "    X_d = X_d.fillna(\"other\")\n",
    "    X_e = X_e.fillna(\"other\")\n",
    "    \n",
    "    y = X_d.quality\n",
    "    X_d = X_d.drop(columns=[\"quality\"])\n",
    "    \n",
    "    df = pd.concat([X_d,X_e])\n",
    "    \n",
    "    df_enc = pd.get_dummies(df)\n",
    "    df_enc_scipy = scipy.sparse.csr_matrix(df_enc.values)\n",
    "    \n",
    "    return df_enc_scipy[:X_d.shape[0]], y, df_enc_scipy[X_d.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################  \n",
    "## Document preprocessing\n",
    "##################################\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "punc = ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}',\"%\"]\n",
    "other_sw = ['anywh', 'el', 'elsewh', 'everywh', 'ind', 'otherwi', 'plea', 'somewh','abov', \n",
    "            'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', \n",
    "            'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', \n",
    "            'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', \n",
    "            'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', \n",
    "            'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', \n",
    "            'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', \n",
    "            'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', \n",
    "            'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', \n",
    "            'wherev', 'whi', 'yourselv']\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(punc).union(other_sw)\n",
    "\n",
    "\n",
    "def preprocessText(text):\n",
    "    t = re.sub('[^A-Za-zàèéìòù]+', ' ', text)\n",
    "    t = re.sub('[A-Z]+', lambda m: m.group(0).lower(), t)\n",
    "    t = ' '.join(w for w in t.split() if w not in stop_words) \n",
    "    t = [stemmer.stem(i) for i in t.split()]\n",
    "    t = ' '.join(output_stemming)\n",
    "    return output_stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing α "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "## Preprocessing - removing the outliers : α\n",
    "####################################################\n",
    "\n",
    "# load datasets\n",
    "X_dev = loadData('dev.tsv')\n",
    "X_eval = loadData('eval.tsv')\n",
    "\n",
    "# drop duplicates\n",
    "X_dev = X_dev.drop_duplicates()\n",
    "\n",
    "# 1.5(IQR) Rule for detecting the outliers thresholds\n",
    "t = X_dev[\"quality\"].quantile(0.75) - X_dev[\"quality\"].quantile(0.25)\n",
    "min_t = X_dev[\"quality\"].quantile(0.25) - 1.5 * t\n",
    "max_t = X_dev[\"quality\"].quantile(0.75) + 1.5 * t\n",
    "\n",
    "# filter\n",
    "X_d_filtered = X_dev[X_dev[\"quality\"] >= min_t]\n",
    "X_d_filtered = X_d_filtered[X_d_filtered[\"quality\"] <= max_t]\n",
    "\n",
    "## POI ELIMINARE - SOLO PER REPORT\n",
    "params = {\n",
    "  \"min_df\": [1], \n",
    "  \"max_df\": [0.4],\n",
    "  \"ngram_range\": [(1,4)]\n",
    "}\n",
    "\n",
    "for config in ParameterGrid(params):\n",
    "    pipe = Pipeline([\n",
    "              ('count', CountVectorizer(**config,  token_pattern=r'\\b[^\\d\\W]+\\b' )), \n",
    "              ('tfid', TfidfTransformer())\n",
    "    ])\n",
    "    \n",
    "    dev_vec = pipe.fit_transform(description_train.description_cleaned)\n",
    "\n",
    "eval_vec = pipe.transform(description_test.description_cleaned) \n",
    "\n",
    "X_conc_dev = hstack((X_dev_prep, dev_vec))\n",
    "X_conc_eval = hstack((X_eval_prep, eval_vec))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "models = [LinearRegression(),,SGDRegressor()]\n",
    "targets = [\"LinearRegression\",\"SGDRegressor\"]\n",
    "\n",
    "scores = evaluateModels(models,targets,X_dev_prep,y)\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(scores), ax=ax,palette=\"OrRd_r\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"R2_Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing β"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "####################################################\n",
    "## Preprocessing - without removing the outliers : β\n",
    "####################################################\n",
    "\n",
    "\n",
    "# load datasets\n",
    "X_dev = loadData('dev.tsv')\n",
    "X_eval = loadData('eval.tsv')\n",
    "\n",
    "# drop duplicates\n",
    "X_dev = X_dev.drop_duplicates()\n",
    "\n",
    "# encode and handle np.nan\n",
    "X_dev_prep, y, X_eval_prep = preprocessing(X_dev,X_eval)\n",
    "\n",
    "# extract the descriptions\n",
    "description_train = X_dev[[\"description\"]].copy()\n",
    "description_test = X_eval[[\"description\"]].copy()\n",
    "\n",
    "# clean the descriptions\n",
    "description_train['description_cleaned'] = description_train['description'].apply(lambda x: preprocessText(x)) \n",
    "description_test['description_cleaned'] = description_test['description'].apply(lambda x: preprocessText(x)) \n",
    "description_train.drop(columns=[\"description\"],inplace=True)\n",
    "description_test.drop(columns=[\"description\"],inplace=True)\n",
    "\n",
    "params = {\n",
    "  \"min_df\": [1], \n",
    "  \"max_df\": [0.4],\n",
    "  \"ngram_range\": [(1,4)]\n",
    "}\n",
    "\n",
    "for config in ParameterGrid(params):\n",
    "    pipe = Pipeline([\n",
    "              ('count', CountVectorizer(**config,  token_pattern=r'\\b[^\\d\\W]+\\b' )), \n",
    "              ('tfid', TfidfTransformer())\n",
    "    ])\n",
    "    \n",
    "    dev_vec = pipe.fit_transform(description_train.description_cleaned)\n",
    "\n",
    "eval_vec = pipe.transform(description_test.description_cleaned) \n",
    "\n",
    "X_conc_dev = hstack((X_dev_prep, dev_vec))\n",
    "X_conc_eval = hstack((X_eval_prep, eval_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "\n",
    "models = [LinearRegression(),,SGDRegressor()]\n",
    "targets = [\"LinearRegression\",\"SGDRegressor\"]\n",
    "\n",
    "scores = evaluateModels(models,targets,X_dev_prep,y)\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(scores), ax=ax,palette=\"OrRd_r\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"R2_Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doGridSearch(model,hyperparams,X,y):\n",
    "    \n",
    "    gs = GridSearchCV(estimator=model,  \n",
    "                         param_grid=hyperparams,\n",
    "                         scoring='r2',\n",
    "                         cv=3,\n",
    "                         n_jobs=4,\n",
    "                         verbose=True)\n",
    "\n",
    "    gs.fit(X, y)\n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "## Grid search linear regression\n",
    "####################################################\n",
    "\n",
    "hyperparams_LR = {\n",
    "    'fit_intercept' : [True,False],\n",
    "    'normalize' : [True,False]\n",
    "}\n",
    "\n",
    "gs_lr = doGridSearch(LinearRegression(), \"LinearRegression\",hyperparams_LR,train_supremo,y)\n",
    "\n",
    "print(f\"Best params:\\t{gs_lr.best_params_}\")\n",
    "print(f\"Best score:\\t{gs_lr.best_score_}\")\n",
    "\n",
    "y_pred_lr = gs_lr.predict(test_supremo)\n",
    "get_final_csv(list(X_eval.index),y_pred_lr,\"submit-linear-regression.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "## Grid search SGD Regressor\n",
    "####################################################\n",
    "\n",
    "hyperparams_SGD = {\n",
    "    'loss' : ['squared_loss','huber'],\n",
    "    'penalty' : ['l1','l2',None],\n",
    "    'alpha' : np.logspace(-5, 0, 6),\n",
    "    'eta0' : [0.01, 0.1]\n",
    "}\n",
    "\n",
    "gs_sgd = doGridSearch(SGDRegressor(max_iter=10000), \"SGDRegressor\",hyperparams_SGD,train_supremo,y)\n",
    "print(f\"Best params:\\t{gs_sgd.best_params_}\")\n",
    "print(f\"Best score:\\t{gs_sgd.best_score_}\")\n",
    "\n",
    "y_pred_sgd = gs_sgd.predict(test_supremo)\n",
    "get_final_csv(list(X_eval.index),y_pred_sgd,\"submit-sgd-regressor.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model used for the final score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
