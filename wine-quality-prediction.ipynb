{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wine quality prediction\n",
    "\n",
    "## Import and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(directory):\n",
    "    df = pd.read_csv(directory,sep=\"\\t\")\n",
    "    return df\n",
    "\n",
    "def get_final_csv(ids, y, filename):\n",
    "    pd.DataFrame(dict(Id = ids,Predicted = y)).to_csv(filename,sep=\",\",index=False)\n",
    "\n",
    "def evaluateModels(models,targets,X,y):\n",
    "    \n",
    "    scores = pd.DataFrame()\n",
    "    \n",
    "    for model,target in zip(models,targets):\n",
    "        cv = RepeatedKFold(n_splits=3, n_repeats=1, random_state=42)\n",
    "        scores[target] = cross_val_score(model, X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "        \n",
    "        print(f\"{target} ended up\")\n",
    "        \n",
    "    return scores\n",
    "\n",
    "\"\"\"\n",
    "    1) OneHot encoding\n",
    "\"\"\"\n",
    "def preprocessingV1(X_d,X_e):\n",
    "    \n",
    "    X_d = X_d.drop(columns=[\"region_2\",\"description\"])\n",
    "    X_e = X_e.drop(columns=[\"region_2\",\"description\"])\n",
    "    \n",
    "    X_d = X_d.fillna(\"other\")\n",
    "    X_e = X_e.fillna(\"other\")\n",
    "    \n",
    "    y = X_d.quality\n",
    "    X_d = X_d.drop(columns=[\"quality\"])\n",
    "    \n",
    "    df = pd.concat([X_d,X_e])\n",
    "    \n",
    "    df_enc = pd.get_dummies(df)\n",
    "    df_enc_scipy = scipy.sparse.csr_matrix(df_enc.values)\n",
    "    \n",
    "    return df_enc_scipy[:X_d.shape[0]], y, df_enc_scipy[X_d.shape[0]:]\n",
    "\n",
    "\"\"\"\n",
    "    2) OneHot encoding + PCA\n",
    "\"\"\"\n",
    "def preprocessingV2(X_d,X_e):\n",
    "    \n",
    "    X_d = X_d.drop(columns=[\"region_2\",\"description\"])\n",
    "    X_e = X_e.drop(columns=[\"region_2\",\"description\"])\n",
    "    \n",
    "    X_d = X_d.fillna(\"other\")\n",
    "    X_e = X_e.fillna(\"other\")\n",
    "    \n",
    "    y = X_d.quality\n",
    "    X_d = X_d.drop(columns=[\"quality\"])\n",
    "    \n",
    "    df = pd.concat([X_d,X_e])\n",
    "    df_enc = pd.get_dummies(df)\n",
    "    \n",
    "    pca = PCA(n_components = 0.95)\n",
    "    df_enc_reduced = pca.fit_transform(df_enc)\n",
    "    df_sparse = scipy.sparse.csr_matrix(df_enc_reduced.values)\n",
    "    \n",
    "    return df_sparse[:X_d.shape[0]], y, df_sparse[X_d.shape[0]:]\n",
    "\n",
    "\"\"\"\n",
    "    3) OneHot encoding without outliers\n",
    "\"\"\"\n",
    "def preprocessingV3(X_d,X_e):\n",
    "    \n",
    "    X_d = X_d.drop(columns=[\"region_2\",\"description\"])\n",
    "    X_e = X_e.drop(columns=[\"region_2\",\"description\"])\n",
    "    \n",
    "    X_d = X_d.fillna(\"other\")\n",
    "    X_e = X_e.fillna(\"other\")\n",
    "    \n",
    "    # 1.5(IQR) Rule for detecting the outliers\n",
    "    t = X_d[\"quality\"].quantile(0.75) - X_d[\"quality\"].quantile(0.25)\n",
    "    min_t = X_d[\"quality\"].quantile(0.25) - 1.5 * t\n",
    "    max_t = X_d[\"quality\"].quantile(0.75) + 1.5 * t\n",
    "    \n",
    "    X_d_filtered = X_d[X_d[\"quality\"] >= min_t]\n",
    "    X_d_filtered = X_d_filtered[X_d_filtered[\"quality\"] <= max_t]\n",
    "    \n",
    "    y = X_d_filtered.quality\n",
    "    \n",
    "    df = pd.concat([X_d_filtered,X_e])\n",
    "    \n",
    "    df_enc = pd.get_dummies(df)\n",
    "    df_enc_scipy = scipy.sparse.csr_matrix(df_enc.values)\n",
    "    \n",
    "    return df_enc_scipy[:X_d_filtered.shape[0]], y, df_enc_scipy[X_d_filtered.shape[0]:]\n",
    "\n",
    "\"\"\"\n",
    "    3) OneHot encoding without outliers\n",
    "\"\"\"\n",
    "def preprocessingV3(X_d,X_e):\n",
    "    \n",
    "    X_d = X_d.drop(columns=[\"region_2\",\"description\"])\n",
    "    X_e = X_e.drop(columns=[\"region_2\",\"description\"])\n",
    "    \n",
    "    X_d = X_d.fillna(\"other\")\n",
    "    X_e = X_e.fillna(\"other\")\n",
    "    \n",
    "    # 1.5(IQR) Rule for detecting the outliers\n",
    "    t = X_d[\"quality\"].quantile(0.75) - X_d[\"quality\"].quantile(0.25)\n",
    "    min_t = X_d[\"quality\"].quantile(0.25) - 1.5 * t\n",
    "    max_t = X_d[\"quality\"].quantile(0.75) + 1.5 * t\n",
    "    \n",
    "    X_d_filtered = X_d[X_d[\"quality\"] >= min_t]\n",
    "    X_d_filtered = X_d_filtered[X_d_filtered[\"quality\"] <= max_t]\n",
    "    \n",
    "    y = X_d_filtered.quality\n",
    "    \n",
    "    df = pd.concat([X_d_filtered,X_e])\n",
    "    \n",
    "    df_enc = pd.get_dummies(df)\n",
    "    df_enc_scipy = scipy.sparse.csr_matrix(df_enc.values)\n",
    "    \n",
    "    return df_enc_scipy[:X_d_filtered.shape[0]], y, df_enc_scipy[X_d_filtered.shape[0]:]\n",
    "\n",
    "\"\"\"\n",
    "    4) OneHot encoding without duplicates\n",
    "\"\"\"\n",
    "def preprocessingV4(X_d,X_e):\n",
    "    \n",
    "    X_d = X_d.drop(columns=[\"region_2\",\"description\"])\n",
    "    X_e = X_e.drop(columns=[\"region_2\",\"description\"])\n",
    "    \n",
    "    X_d = X_d.fillna(\"other\")\n",
    "    X_d = X_d.drop_duplicates()\n",
    "    X_e = X_e.fillna(\"other\")\n",
    "    \n",
    "    y = X_d.quality\n",
    "    X_d = X_d.drop(columns=[\"quality\"])\n",
    "    \n",
    "    df = pd.concat([X_d,X_e])\n",
    "    \n",
    "    df_enc = pd.get_dummies(df)\n",
    "    df_enc_scipy = scipy.sparse.csr_matrix(df_enc.values)\n",
    "    \n",
    "    return df_enc_scipy[:X_d.shape[0]], y, df_enc_scipy[X_d.shape[0]:]\n",
    "\n",
    "\"\"\"\n",
    "    5) OneHot encoding of the top 80% elements per feature\n",
    "\"\"\"\n",
    "def preprocessingV5(X_d,X_e,labels):\n",
    "    \n",
    "    X_d = X_d.drop(columns=[\"region_2\",\"description\"])\n",
    "    X_e = X_e.drop(columns=[\"region_2\",\"description\"])\n",
    "    \n",
    "    X_d = X_d.fillna(\"other\")\n",
    "    X_e = X_e.fillna(\"other\")\n",
    "    \n",
    "    y = X_d.quality\n",
    "    X_d = X_d.drop(columns=[\"quality\"])\n",
    "    \n",
    "    df = pd.concat([X_d,X_e])\n",
    "    \n",
    "    for label in labels:\n",
    "        \n",
    "        top_labels_index = df[label].value_counts().index\n",
    "        top_labels_length = len(df[label].value_counts().index)\n",
    "        thresh = round(top_labels_length * 80 / 100)\n",
    "        thresh = top_labels_length\n",
    "        \n",
    "        top = df[label].isin(top_labels_index[:thresh])\n",
    "        df.loc[~top, label] = \"other\"\n",
    "    \n",
    "    df_enc = scipy.sparse.csr_matrix(pd.get_dummies(df).values)\n",
    "    \n",
    "    return df_enc[:X_d.shape[0]], y, df_enc[X_d.shape[0]:]\n",
    "\n",
    "## extra\n",
    "models = [LinearRegression(),RandomForestRegressor(),SGDRegressor()]\n",
    "targets = [\"Linear Regression\",\"Random Forest\",\"SGD Regressor\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## OneHot Encoding\n",
    "########################################\n",
    "\n",
    "%%time\n",
    "\n",
    "X_dev_v1 = loadData('Dataset/dev.tsv')\n",
    "X_eval_v1 = loadData('Dataset/eval.tsv')\n",
    "\n",
    "X_dev_v1_prep, y1, X_eval_v1_prep = preprocessingV1(X_dev_v1,X_eval_v1)\n",
    "\n",
    "scores = evaluateModels(models,targets,X_dev_v1_prep,y1)\n",
    "scores.to_csv(\"scores-v1.csv\",sep=\",\",index=False)\n",
    "\n",
    "X_dev_v1_prep.shape, y1.shape, X_eval_v1_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_1 = RandomForestRegressor()\n",
    "rf_1.fit(X_dev_v1_prep,y1)\n",
    "\n",
    "y_pred_1 = rf_1.predict(X_eval_v1_prep)\n",
    "get_csv(list(X_eval_v1.index),y_pred_1,\"submission_prep_v1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## OneHot Encoding + PCA\n",
    "########################################\n",
    "\n",
    "%%time\n",
    "\n",
    "X_dev_v2 = loadData('Dataset/dev.tsv')\n",
    "X_eval_v2 = loadData('Dataset/eval.tsv')\n",
    "\n",
    "X_dev_v2_prep, y2, X_eval_v2_prep = preprocessingV2(X_dev_v2,X_eval_v2)\n",
    "\n",
    "scores_2= evaluateModels(models,targets,X_dev_v2_prep,y2)\n",
    "scores_2.to_csv(\"scores-v2.csv\",sep=\",\",index=False)\n",
    "\n",
    "X_dev_v2_prep.shape, y2.shape, X_eval_v2_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_2 = RandomForestRegressor()\n",
    "rf_2.fit(X_dev_v2_prep,y2)\n",
    "\n",
    "y_pred_2 = rf_2.predict(X_eval_v2_prep)\n",
    "get_csv(list(X_eval_v2.index),y_pred_2,\"submission_prep_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## OneHot Encoding + removing outliers\n",
    "########################################\n",
    "\n",
    "%%time\n",
    "\n",
    "X_dev_v3 = loadData('Dataset/dev.tsv')\n",
    "X_eval_v3 = loadData('Dataset/eval.tsv')\n",
    "\n",
    "X_dev_v3_prep, y3, X_eval_v3_prep = preprocessingV3(X_dev_v3,X_eval_v3)\n",
    "\n",
    "scores_3 = evaluateModels(models,targets,X_dev_v3_prep,y3)\n",
    "scores_3.to_csv(\"scores-v3.csv\",sep=\",\",index=False)\n",
    "\n",
    "X_dev_v3_prep.shape, y3.shape, X_eval_v3_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_3 = RandomForestRegressor()\n",
    "rf_3.fit(X_dev_v3_prep,y3)\n",
    "\n",
    "y_pred_3 = rf_3.predict(X_eval_v3_prep)\n",
    "get_csv(list(X_eval_v3.index),y_pred_3,\"submission_prep_v3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## OneHot Encoding + removing duplicates\n",
    "########################################\n",
    "\n",
    "X_dev_v4 = loadData('Dataset/dev.tsv')\n",
    "X_eval_v4 = loadData('Dataset/eval.tsv')\n",
    "\n",
    "X_dev_v4_prep, y4, X_eval_v4_prep = preprocessingV4(X_dev_v4,X_eval_v4)\n",
    "\n",
    "scores_4 = evaluateModels(models,targets,X_dev_v4_prep,y4)\n",
    "scores_4.to_csv(\"scores-v4.csv\",sep=\",\",index=False)\n",
    "\n",
    "X_dev_v4_prep.shape, y4.shape, X_eval_v4_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_4 = RandomForestRegressor()\n",
    "rf_4.fit(X_dev_v4_prep,y4)\n",
    "\n",
    "y_pred_4 = rf_4.predict(X_eval_v4_prep)\n",
    "get_csv(list(X_eval_v4.index),y_pred_4,\"submission_prep_v4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing testing - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## OneHot Encoding of top 80% elements\n",
    "########################################\n",
    "\n",
    "X_dev_v5 = loadData('Dataset/dev.tsv')\n",
    "X_eval_v5 = loadData('Dataset/eval.tsv')\n",
    "\n",
    "X_dev_v5_prep, y5, X_eval_v5_prep = preprocessingV5(X_dev_v5,X_eval_v5)\n",
    "\n",
    "scores_5 = evaluateModels(models,targets,X_dev_v5_prep,y5)\n",
    "scores_5.to_csv(\"scores-v5.csv\",sep=\",\",index=False)\n",
    "\n",
    "X_dev_v5_prep.shape, y5.shape, X_eval_v5_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_5 = RandomForestRegressor()\n",
    "rf_5.fit(X_dev_v5_prep,y5)\n",
    "\n",
    "y_pred_5 = rf_5.predict(X_eval_v5_prep)\n",
    "get_csv(list(X_eval_v5.index),y_pred_5,\"submission_prep_v5.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
