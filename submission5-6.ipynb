{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
    "\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer \n",
    "import category_encoders\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(directory):\n",
    "    df = pd.read_csv(directory,sep=\"\\t\")\n",
    "    return df\n",
    "\n",
    "def getSentimentLabel(X): \n",
    "    avg = np.mean(X['quality'])\n",
    "    X['sentiment'] = X['quality'].apply(lambda x: np.min([2,int(x/30)]))\n",
    "    \n",
    "    return X\n",
    "    \n",
    "## BinatyEncoding\n",
    "def doPreproc(X_d,X_e,labels):\n",
    "       \n",
    "    df = pd.concat([X_d,X_e])\n",
    "\n",
    "    encoder = category_encoders.BinaryEncoder(cols=labels)\n",
    "    df = encoder.fit_transform(df)\n",
    "    \n",
    "    ev = df[df['quality'].isna()].drop(columns=['quality'])\n",
    "    dev = df.dropna(subset=['quality'])\n",
    "\n",
    "    return dev, ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOADING - ENCODING - SENTIMENT LABELING\n",
    "X_dev = loadData('Dataset/dev.tsv')\n",
    "X_eval = loadData('Dataset/eval.tsv')\n",
    "X_dev = X_dev.drop_duplicates()\n",
    "X_dev = X_dev.drop(columns=['region_2'])\n",
    "X_eval = X_eval.drop(columns=['region_2'])\n",
    "\n",
    "\n",
    "X_prep_v, X_eval_v = doPreproc(X_dev,X_eval,['country','province','variety',\n",
    "                                                  'winery','region_1','designation'])\n",
    "\n",
    "X_prep_v = getSentimentLabel(X_prep_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords as sw\n",
    "import Stemmer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doLogisticRegression(x,y):\n",
    "    \n",
    "    model = LogisticRegression(max_iter=10000)\n",
    "    \n",
    "    parameters ={\n",
    "        'C':np.logspace(-3,3,7), \n",
    "        'penalty':[\"l1\",\"l2\"], # l1 lasso l2 ridge\n",
    "        'random_state' : [42],\n",
    "        'n_jobs' : [-1]\n",
    "    } \n",
    "    \n",
    "    gs = GridSearchCV(estimator=model,  \n",
    "                         param_grid=parameters,\n",
    "                         scoring='accuracy',\n",
    "                         cv=5,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "    gs.fit(x, y)\n",
    "    print(\"\\nLOGISTIC REGRESSION: \")\n",
    "    print(f\"Best parameters = {gs.best_params_}\")\n",
    "    print(f\"Best score = {gs.best_score_ }\")\n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doMultinomialNB(x,y):\n",
    "    \n",
    "    model = MultinomialNB()\n",
    "    \n",
    "    parameters =  {\n",
    "        'alpha': np.linspace(0.5, 1.5, 6),\n",
    "        'fit_prior': [True, False]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(estimator=model,  \n",
    "                         param_grid=parameters,\n",
    "                         scoring='accuracy',\n",
    "                         cv=5,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "    gs.fit(x, y)\n",
    "    print(\"\\nMULTINOMIAL NB: \")\n",
    "    print(f\"Best parameters = {gs.best_params_}\")\n",
    "    print(f\"Best score = {gs.best_score_ }\")\n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doSGDClassifier(x,y):\n",
    "    \n",
    "    model = SGDClassifier(max_iter=1000)\n",
    "    \n",
    "    parameters =  {\n",
    "        \"loss\" : [\"hinge\", \"log\",\"squared_hinge\", \"modified_huber\"],\n",
    "        \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "        \"penalty\" : [\"l2\", \"l1\", \"none\"],\n",
    "        \"n_jobs\" : [-1],\n",
    "        \"random_state\" : [42]\n",
    "    }\n",
    "    \n",
    "    gs = GridSearchCV(estimator=model,  \n",
    "                         param_grid=parameters,\n",
    "                         scoring='accuracy',\n",
    "                         cv=5,\n",
    "                         n_jobs=-1)\n",
    "\n",
    "    gs.fit(x, y)\n",
    "    print(\"\\nSGDClassifier: \")\n",
    "    print(f\"Best parameters = {gs.best_params_}\")\n",
    "    print(f\"Best score = {gs.best_score_ }\")\n",
    "    \n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(X_eval['description'].values) \n",
    "b = list(X_dev['description'].values)\n",
    "\n",
    "X_sentiment = a + b\n",
    "y_sentiment_train = X_prep_v['sentiment']\n",
    "\n",
    "stop_words_list = sw.words('english') + [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo', 'would']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_naive = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None, \n",
    "                              stop_words=stop_words_list, ngram_range=(1,2))\n",
    "\n",
    "X_tfidf = tfidf_naive.fit_transform(X_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf[:X_dev.shape[0]], y_sentiment_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7826127863762525\n"
     ]
    }
   ],
   "source": [
    "model = SGDClassifier()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 21257})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7791080588918529\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "# gs_SGDClassifier = doSGDClassifier(X_naive_complete[:X_dev.shape[0]],y_sentiment_train)\n",
    "\n",
    "params = {\n",
    "    \"loss\" : [\"hinge\", \"log\",\"squared_hinge\", \"modified_huber\"],\n",
    "    \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n",
    "    \"penalty\" : [\"l2\", \"l1\", \"none\"],\n",
    "    \"n_jobs\" : [-1],\n",
    "    \"random_state\" : [42]\n",
    "}\n",
    "\n",
    "model = SGDClassifier(max_iter=1000)\n",
    "clf = GridSearchCV(model, param_grid=params, n_jobs=-1, scoring='accuracy',cv=5)\n",
    "clf.fit(X_tfidf[:X_dev.shape[0]], y_sentiment_train)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf_LR = doLogisticRegression(X_tfidf[:X_dev.shape[0]], y_sentiment_train)\n",
    "#clf_MNB = doMultinomialNB(X_tfidf[:X_dev.shape[0]], y_sentiment_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = SGDClassifier()\n",
    "model_final.fit(X_tfidf[:X_dev.shape[0]], y_sentiment_train)\n",
    "sentiment_predicted = model_final.predict(X_tfidf[X_dev.shape[0]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_eval_v['sentiment'] = sentiment_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection\n",
    "\\# -- specificare la misura di riferimento (accuracy o altro) <br /><br />\n",
    "In order to tune the best models, we tested #tot different classifiers with their default hyperparameters through the Repeated K-Fold Cross Validation. This gives a more “robust” model assessment score rather than the fairly well known K-Fold Cross Validation, because it run several times. In this case we used 5 folds and 10 ierations. The algorithms that we tested are: \n",
    "- **\n",
    "- **\n",
    "\n",
    "The output of the the Cross Validation phase can be clearly seen in Figure # . So we decided to tune the \\\\ and the \\\\ classifiers trough the Grid Search, as explained in the next section. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModels(models, targets,X,y):\n",
    "    \n",
    "    scores = pd.DataFrame()\n",
    "    \n",
    "    for model,target in zip(models,targets):\n",
    "        cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=42)\n",
    "        scores[target] = cross_val_score(model, X, y, scoring='r2', cv=cv, n_jobs=-1)\n",
    "        \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'R2_Score')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "randomforest = RandomForestRegressor()\n",
    "models = [randomforest]\n",
    "targets = [\"RandomForest\"]\n",
    "\n",
    "\n",
    "scores = evaluateModels(models,targets,X,y)\n",
    "sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(scores))\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"R2_Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "In order to improve the performances of the selected models we used the GridSearchCV that performs a Cross Validation over all the combinations of a given set of hyperparameters. Since we had enough data, we used the hold out technique, so we considered 80% for the train data and the remaining 20% for the testing the models. \n",
    "\n",
    "## Results\n",
    "The results of the hyperparameters tuning can be seen in Table ##. Apparently they all outperformed their naive solutions and \\[brodo\\] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X_prep_v.quality\n",
    "X = X_prep_v.drop(columns=['quality','description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doGridSearch(model,model_name,hyperparams,X,y):\n",
    "    gs = GridSearchCV(estimator=model,  \n",
    "                         param_grid=hyperparams,\n",
    "                         scoring='r2',\n",
    "                         cv=4,\n",
    "                         n_jobs=6,\n",
    "                         verbose=True)\n",
    "\n",
    "    gs.fit(X, y)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams_RF = {\n",
    "    \"n_estimators\": [800],\n",
    "    #\"criterion\": [\"mse\", \"mae\"],\n",
    "    \"max_features\": [\"auto\"],\n",
    "    #\"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"random_state\": [42],# always use the samet random seed\n",
    "    \"n_jobs\": [-1],# for parallelization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85028, 72), (85028,))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   4 out of   4 | elapsed:  8.2min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   39.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  2.7min finished\n"
     ]
    }
   ],
   "source": [
    "gs_800 = doGridSearch(RandomForestRegressor(verbose=True), \"RandomForestRegressor\",hyperparams_RF,X.drop(columns=['sentiment']),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\t{'max_features': 'auto', 'n_estimators': 800, 'n_jobs': -1, 'random_state': 42}\n",
      "Best score:\t0.6517462560340501\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best params:\\t{gs_800.best_params_}\")\n",
    "print(f\"Best score:\\t{gs_800.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((85028, 71), (30186, 71))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.drop(columns=['sentiment']).shape, X_eval_v.drop(columns=['description','sentiment']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 184 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done 434 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=8)]: Done 700 out of 700 | elapsed:    1.9s finished\n"
     ]
    }
   ],
   "source": [
    "y_pred  = gs_700.predict(X_eval_v.drop(columns=['description','sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv(ids, y):\n",
    "    pd.DataFrame(dict(Id = ids,Predicted = y)).to_csv(\"submission6.csv\",sep=\",\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_csv(list(X_eval.index),y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy history\n",
    "\n",
    "### Submission 1 : 0.756 | 2021-01-11 16:24:05.639162 \t\n",
    "* Preprocessing: hash <br />\n",
    "* Model : Random Forest <br />\n",
    "* Hyperparams: {'max_features': 'sqrt', 'n_estimators': 500, 'n_jobs': -1, 'random_state': 42} <br />\n",
    "* features : country,province,region_1, variety, winery, length_description <br />\n",
    "\n",
    "### Submission 2 : 0.807 | 2021-01-12 08:14:14.977122\t\n",
    "* Preprocessing: hash <br />\n",
    "* Model : Random Forest <br />\n",
    "* Hyperparams: {'max_features': 'auto', 'n_estimators': 500, 'n_jobs': -1, 'random_state': 42}\n",
    "* features : country,province,region_1, variety, winery, designation <br />\n",
    "\n",
    "### Submission 3 : 0.822 | 2021-01-12 08:56:40.440284\n",
    "* Preprocessing: BinaryEncoding <br />\n",
    "* Model : Random Forest <br />\n",
    "* Hyperparams: {'max_features': 'auto', 'n_estimators': 500, 'n_jobs': -1, 'random_state': 42}\n",
    "* features : country,province,region_1, variety, winery, designation <br />\n",
    "\n",
    "### Submission 5 : 0.512 | 2021-01-13 09:24:57.953673\n",
    "* Preprocessing: BinaryEncoding + Sentiment Analysis <br />\n",
    "* Model : Random Forest Regressor + SGDClassifier <br />\n",
    "* Hyperparams: {'max_features': 'auto', 'n_estimators': 500, 'n_jobs': -1, 'random_state': 42}\n",
    "* features : country,province,region_1, variety, winery, designation, sentiment <br />\n",
    "* sentiment : X['sentiment'] = X['quality'].apply(lambda x: np.min([2,int(x/30)]))\n",
    "\n",
    "### Submission 6 : 0.822 | 2021-01-13 09:45:30.360426\n",
    "* Preprocessing: BinaryEncoding <br />\n",
    "* Model : Random Forest <br />\n",
    "* Hyperparams: {'max_features': 'auto', 'n_estimators': '700', 'n_jobs': -1, 'random_state': 42}\n",
    "* features : country,province,region_1, variety, winery, designation <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## //Test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
